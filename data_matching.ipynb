{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA MATCHING AND CLEANING OF MATCHED DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Data matching in this chapter contains two sections\n",
    "\n",
    "\n",
    "### 1) Data matching to generate coarse list of matched data (risk of duplicates data):\n",
    "This is to show the matched data between T1 and T2. <br> List of matched data is obtained by matching the same subject, visit, and acquisition date for each group of AD, MCI, and CN. \n",
    "\n",
    "\n",
    "### 2) Matched data cleaning to generate list of final unique and balanced matched data (no duplicate)\n",
    "This section is to clean the duplicated data found in matched data of T1 and T2 <br> There are also two steps here:<br><br>\n",
    "<b>1. Removing duplicated data to tenerate cleaned list of matched data</b>  \n",
    "    - To create the clean list of matched data, we remove the duplicated data from matched data list in T1 and T2<br>\n",
    "    - The information and list of duplicated data is generated from `Metadata_Matched_Nolimit.xlsx` on section `duplicated_list`. The idea is to compare between availability of subjects from T1 and T2 list of cleaned matched data.\n",
    " \n",
    "    \n",
    "<b>2. Create unique and balanced matched data list</b> : <br>\n",
    "    -  This is done by adding missed data for T1 and dropping the overflow data for T2<br>\n",
    "    -  Since the duplicated values are all dropped in T1, there are some sets of data excluded in T1, but included in T2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from nibabel.testing import data_path\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt \n",
    "import sys\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from volumentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetaDict(input_df):\n",
    "    meta_dict = {} #dict\n",
    "    # meta_dict[0].append(meta_df.loc[:,\"Image Data ID\"])\n",
    "    meta_dict[\"ImageID\"] = input_df.loc[:,\"Image Data ID\"]\n",
    "    meta_dict[\"SubjectID\"] = input_df.loc[:,\"Subject\"]\n",
    "    meta_dict[\"Group\"] = input_df.loc[:,\"Group\"]\n",
    "    meta_dict[\"Sex\"] = input_df.loc[:,\"Sex\"]\n",
    "    meta_dict[\"Age\"] = input_df.loc[:,\"Age\"]\n",
    "    meta_dict[\"Visit\"] = input_df.loc[:,\"Visit\"]\n",
    "    meta_dict[\"Modality\"] = input_df.loc[:,\"Modality\"]\n",
    "    meta_dict[\"Description\"] = input_df.loc[:,\"Description\"]\n",
    "    meta_dict[\"Type\"] = input_df.loc[:,\"Type\"]\n",
    "    meta_dict[\"AcqData\"] = input_df.loc[:,\"Acq Date\"]\n",
    "    meta_dict[\"Format\"] = input_df.loc[:,\"Format\"]\n",
    "    return meta_dict\n",
    "\n",
    "def getMetaString(input_df):\n",
    "# meta_series = meta_df.loc[:,\"Series.ID\"]\n",
    "# meta_study = meta_df.loc[:,\"Study.ID\"]\n",
    "    meta_image = input_df.loc[:,\"Image Data ID\"]\n",
    "    meta_subject = input_df.loc[:,\"Subject\"]\n",
    "    meta_date = input_df.loc[:,\"Acq Date\"]\n",
    "    meta_visit = input_df.loc[:,\"Visit\"]\n",
    "    meta_group = input_df.loc[:,\"Group\"]\n",
    "    \n",
    "    meta_combined= []\n",
    "    meta_combined.clear()\n",
    "    imgIds = []\n",
    "    imgIds.clear()\n",
    "    i=0\n",
    "    for i in range(0,len(meta_subject)):\n",
    "        # combined = str(meta_subject[i])+\"-\"+str(meta_series[i])+\"-\"+str(meta_image[i])\n",
    "        # if \"CN\" in meta_group[i]:\n",
    "        #     # print(\"yes\")\n",
    "        #     meta_combined.append(meta_subject[i]+\"-\"+str(meta_visit[i])+\"-\"+str(meta_date[i]))\n",
    "        # else:\n",
    "        combined = str(meta_subject[i])+\"-\"+str(meta_visit[i])+\"-\"+str(meta_date[i])\n",
    "        # combined = str(meta_visit[i]) \n",
    "        meta_combined.append(combined)\n",
    "        imgIds.append(meta_image[i])\n",
    "        i+=1\n",
    "    return meta_combined, imgIds\n",
    "\n",
    "def getIntersectFrame(input1, input2, seq=\"T1\"):    \n",
    "    imgArray = []\n",
    "    imgArray.clear()\n",
    "    string1, imgIds1  = getMetaString(input1)\n",
    "    string2, imgIds2= getMetaString(input2)\n",
    "\n",
    "    meta_dict = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    val = 0\n",
    "    for i in range(len(string1)):    \n",
    "        for j in range(len(string2)):\n",
    "            if string1[i]==string2[j]: #Find the intersection\n",
    "                # print(\"T1: {}, T2: {}\".format(meta_image_1[i], meta_image_2[j])\n",
    "                if \"T1\" in seq:\n",
    "                    meta_dict[\"Image Data ID\"].append(input1.loc[i,\"Image Data ID\"])\n",
    "                    meta_dict[\"Subject\"].append(input1.loc[i,\"Subject\"])\n",
    "                    meta_dict[\"Group\"].append(input1.loc[i,\"Group\"])\n",
    "                    meta_dict[\"Sex\"].append(input1.loc[i,\"Sex\"])\n",
    "                    meta_dict[\"Age\"].append(input1.loc[i,\"Age\"])\n",
    "                    meta_dict[\"Visit\"].append(input1.loc[i,\"Visit\"])\n",
    "                    meta_dict[\"Modality\"].append(input1.loc[i,\"Modality\"])\n",
    "                    meta_dict[\"Description\"].append(input1.loc[i,\"Description\"])\n",
    "                    meta_dict[\"Type\"].append(input1.loc[i,\"Type\"])\n",
    "                    meta_dict[\"Acq Date\"].append(input1.loc[i,\"Acq Date\"])\n",
    "                    meta_dict[\"Format\"].append( input1.loc[i,\"Format\"])\n",
    "\n",
    "                # if \"T1\" in seq:\n",
    "                #     # imgArray.append(string1[i].split(\"-\")[0])\n",
    "                #     imgArray.append(imgIds1[i])\n",
    "                # else:\n",
    "                    # imgArray.append(imgIds2[j])\n",
    "                else:\n",
    "                    meta_dict[\"Image Data ID\"].append(input2.loc[j,\"Image Data ID\"])\n",
    "                    meta_dict[\"Subject\"].append(input2.loc[j,\"Subject\"])\n",
    "                    meta_dict[\"Group\"].append(input2.loc[j,\"Group\"])\n",
    "                    meta_dict[\"Sex\"].append(input2.loc[j,\"Sex\"])\n",
    "                    meta_dict[\"Age\"].append(input2.loc[j,\"Age\"])\n",
    "                    meta_dict[\"Visit\"].append(input2.loc[j,\"Visit\"])\n",
    "                    meta_dict[\"Modality\"].append(input2.loc[j,\"Modality\"])\n",
    "                    meta_dict[\"Description\"].append(input2.loc[j,\"Description\"])\n",
    "                    meta_dict[\"Type\"].append(input2.loc[j,\"Type\"])\n",
    "                    meta_dict[\"Acq Date\"].append(input2.loc[j,\"Acq Date\"])\n",
    "                    meta_dict[\"Format\"].append( input2.loc[j,\"Format\"])\n",
    "\n",
    "                val+=1\n",
    "                # print(val)\n",
    "                # print(meta)\n",
    "   \n",
    "    # temp_meta_df = pd.DataFrame(meta_dict)  #convert the dict to a pandas DataFrame    \n",
    "    # return imgArray\n",
    "    # return meta_dict\n",
    "\n",
    "        temp_meta_df = pd.DataFrame(meta_dict)  #convert the dict to a pandas DataFrame    \n",
    "    return temp_meta_df\n",
    "\n",
    "def exportMatchedCSV(input_df, seq, cond):\n",
    "    meta_csv_file = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_3T_12_05_2022.csv\".format(seq, cond)\n",
    "    # meta_csv_file = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_3T_12_05_2022_Nonduplicate.csv\".format(seq, cond) #updated in 01/02/2023 thinking about removing duplicate values in matched data csv\n",
    "\n",
    "    with open(meta_csv_file, mode='w') as f:\n",
    "        input_df.to_csv(f)\n",
    "\n",
    "def exportCleanCSV(input_df, seq, cond):\n",
    "    meta_csv_file = \"./TempMeta/Cleaned_Matched_Nolimit_{}w_{}_ADNI1_3T_12_05_2022.csv\".format(seq, cond)\n",
    "    # meta_csv_file = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_3T_12_05_2022_Nonduplicate.csv\".format(seq, cond) #updated in 01/02/2023 thinking about removing duplicate values in matched data csv\n",
    "\n",
    "    with open(meta_csv_file, mode='w') as f:\n",
    "        input_df.to_csv(f)\n",
    "\n",
    "def exportUniqueCSV(input_df, seq, cond):\n",
    "    meta_csv_file = \"./TempMeta/Unique_Matched_Nolimit_{}w_{}_ADNI1_3T_12_05_2022.csv\".format(seq, cond)\n",
    "    # meta_csv_file = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_3T_12_05_2022_Nonduplicate.csv\".format(seq, cond) #updated in 01/02/2023 thinking about removing duplicate values in matched data csv\n",
    "\n",
    "    with open(meta_csv_file, mode='w') as f:\n",
    "        input_df.to_csv(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET MATCHED DATA (COARSE LIST -> DUPLICATE RISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = 3 #1.5 or 3\n",
    "downloadDate = \"12_05_2022\"\n",
    "# meta_path = \"./Metadata/KHU_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "# path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "seq = \"T1\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_1_ad = \"./TempMeta/Cleaned_Ori_Nolimit_{}w_{}_ADNI1_{}T.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_1_mci = \"./TempMeta/Cleaned_Ori_Nolimit_{}w_{}_ADNI1_{}T.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_1_cn = \"./TempMeta/Cleaned_Ori_Nolimit_{}w_{}_ADNI1_{}T.csv\".format(seq, cond, tesla, downloadDate)\n",
    "seq = \"T2\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_2_ad = \"./TempMeta/Cleaned_Ori_Nolimit_{}w_{}_ADNI1_{}T.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_2_mci = \"./TempMeta/Cleaned_Ori_Nolimit_{}w_{}_ADNI1_{}T.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_2_cn = \"./TempMeta/Cleaned_Ori_Nolimit_{}w_{}_ADNI1_{}T.csv\".format(seq, cond, tesla, downloadDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230204-160319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df_1_ad = pd.read_csv(meta_path_1_ad, delimiter=',')\n",
    "meta_df_1_mci = pd.read_csv(meta_path_1_mci, delimiter=',')\n",
    "meta_df_1_cn = pd.read_csv(meta_path_1_cn, delimiter=',')\n",
    "meta_df_2_ad = pd.read_csv(meta_path_2_ad, delimiter=',')\n",
    "meta_df_2_mci = pd.read_csv(meta_path_2_mci, delimiter=',')\n",
    "meta_df_2_cn = pd.read_csv(meta_path_2_cn, delimiter=',')\n",
    "\n",
    "# dict1 = getMetaDict(meta_df_1)\n",
    "# dict2 = getMetaDict(meta_df_2)\n",
    "# string1 = getMetaString(meta_df_1_ad)\n",
    "\n",
    "inter_1_ad = getIntersectFrame(meta_df_1_ad, meta_df_2_ad, \"T1\")\n",
    "inter_1_mci = getIntersectFrame(meta_df_1_mci, meta_df_2_mci, \"T1\")\n",
    "inter_1_cn = getIntersectFrame(meta_df_1_cn, meta_df_2_cn, \"T1\")\n",
    "\n",
    "inter_2_ad = getIntersectFrame(meta_df_1_ad, meta_df_2_ad, \"T2\")\n",
    "inter_2_mci = getIntersectFrame(meta_df_1_mci, meta_df_2_mci, \"T2\")\n",
    "inter_2_cn = getIntersectFrame(meta_df_1_cn, meta_df_2_cn, \"T2\")\n",
    "\n",
    "# inter1 = inter_1_ad + inter_1_mci\n",
    "\n",
    "# exportCSV(interdf1, \"T1\", cond)\n",
    "# exportCSV(interdf2, \"T2\", cond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportMatchedCSV(inter_1_ad, \"T1\", \"AD\")\n",
    "exportMatchedCSV(inter_1_mci, \"T1\", \"MCI\")\n",
    "exportMatchedCSV(inter_1_cn, \"T1\", \"CN\")\n",
    "exportMatchedCSV(inter_2_ad, \"T2\", \"AD\")\n",
    "exportMatchedCSV(inter_2_mci, \"T2\", \"MCI\")\n",
    "exportMatchedCSV(inter_2_cn, \"T2\", \"CN\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEAN DUPLICATE AND BALANCE MATCHED DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean duplicated data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = 3 #1.5 or 3\n",
    "downloadDate = \"12_05_2022\"\n",
    "# meta_path = \"./Metadata/KHU_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "# path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "seq = \"T1\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_1_ad = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_1_mci = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_1_cn =\"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "seq = \"T2\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_2_ad = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_2_mci = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_2_cn = \"./TempMeta/Matched_Nolimit_{}w_{}_ADNI1_{}T_{}.csv\".format(seq, cond, tesla, downloadDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230203-022939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df_1_ad = pd.read_csv(meta_path_1_ad, delimiter=',')\n",
    "meta_df_1_mci = pd.read_csv(meta_path_1_mci, delimiter=',')\n",
    "meta_df_1_cn = pd.read_csv(meta_path_1_cn, delimiter=',')\n",
    "meta_df_2_ad = pd.read_csv(meta_path_2_ad, delimiter=',')\n",
    "meta_df_2_mci = pd.read_csv(meta_path_2_mci, delimiter=',')\n",
    "meta_df_2_cn = pd.read_csv(meta_path_2_cn, delimiter=',')\n",
    "\n",
    "# dict1 = getMetaDict(meta_df_1)\n",
    "# dict2 = getMetaDict(meta_df_2)\n",
    "# string1 = getMetaString(meta_df_1_ad)\n",
    "\n",
    "inter_1_ad = getIntersectFrame(meta_df_1_ad, meta_df_2_ad, \"T1\")\n",
    "inter_1_mci = getIntersectFrame(meta_df_1_mci, meta_df_2_mci, \"T1\")\n",
    "inter_1_cn = getIntersectFrame(meta_df_1_cn, meta_df_2_cn, \"T1\")\n",
    "\n",
    "inter_2_ad = getIntersectFrame(meta_df_2_ad, meta_df_2_ad, \"T2\")\n",
    "inter_2_mci = getIntersectFrame(meta_df_1_mci, meta_df_2_mci, \"T2\")\n",
    "inter_2_cn = getIntersectFrame(meta_df_1_cn, meta_df_2_cn, \"T2\")\n",
    "\n",
    "# inter1 = inter_1_ad + inter_1_mci\n",
    "\n",
    "# exportCSV(interdf1, \"T1\", cond)\n",
    "# exportCSV(interdf2, \"T2\", cond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I65946</td>\n",
       "      <td>067_S_1185</td>\n",
       "      <td>AD</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/07/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I65945</td>\n",
       "      <td>067_S_1185</td>\n",
       "      <td>AD</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE Repeat</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/07/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I37523</td>\n",
       "      <td>032_S_1101</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE</td>\n",
       "      <td>Original</td>\n",
       "      <td>1/25/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I55156</td>\n",
       "      <td>032_S_1101</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/23/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I37524</td>\n",
       "      <td>032_S_1101</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE Repeat</td>\n",
       "      <td>Original</td>\n",
       "      <td>1/25/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>I60917</td>\n",
       "      <td>131_S_0457</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MP-RAGE</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/19/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>I15182</td>\n",
       "      <td>136_S_0299</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE repe</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/12/2006</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>I29121</td>\n",
       "      <td>136_S_0299</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE 3dtfe</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/06/2006</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>I29120</td>\n",
       "      <td>136_S_0299</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE repeat</td>\n",
       "      <td>Original</td>\n",
       "      <td>11/06/2006</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>I15181</td>\n",
       "      <td>136_S_0299</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>MRI</td>\n",
       "      <td>MPRAGE 3dtf</td>\n",
       "      <td>Original</td>\n",
       "      <td>5/12/2006</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Image Data ID     Subject Group Sex  Age  Visit Modality  \\\n",
       "0            0        I65946  067_S_1185    AD   M   63      3      MRI   \n",
       "1            1        I65945  067_S_1185    AD   M   63      3      MRI   \n",
       "2            2        I37523  032_S_1101    AD   F   71      2      MRI   \n",
       "3            3        I55156  032_S_1101    AD   F   71      3      MRI   \n",
       "4            4        I37524  032_S_1101    AD   F   71      2      MRI   \n",
       "..         ...           ...         ...   ...  ..  ...    ...      ...   \n",
       "95          95        I60917  131_S_0457    AD   F   84      4      MRI   \n",
       "96          96        I15182  136_S_0299    AD   F   89      2      MRI   \n",
       "97          97        I29121  136_S_0299    AD   F   90      3      MRI   \n",
       "98          98        I29120  136_S_0299    AD   F   90      3      MRI   \n",
       "99          99        I15181  136_S_0299    AD   F   89      2      MRI   \n",
       "\n",
       "      Description      Type    Acq Date Format  \n",
       "0          MPRAGE  Original   8/07/2007    DCM  \n",
       "1   MPRAGE Repeat  Original   8/07/2007    DCM  \n",
       "2          MPRAGE  Original   1/25/2007    DCM  \n",
       "3          MPRAGE  Original   5/23/2007    DCM  \n",
       "4   MPRAGE Repeat  Original   1/25/2007    DCM  \n",
       "..            ...       ...         ...    ...  \n",
       "95        MP-RAGE  Original   7/19/2007    DCM  \n",
       "96    MPRAGE repe  Original   5/12/2006    DCM  \n",
       "97   MPRAGE 3dtfe  Original  11/06/2006    DCM  \n",
       "98  MPRAGE repeat  Original  11/06/2006    DCM  \n",
       "99    MPRAGE 3dtf  Original   5/12/2006    DCM  \n",
       "\n",
       "[100 rows x 12 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_1_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----Create clean list of matched data by dropping duplicated data\n",
    "\n",
    "#---For T2, duplicated data can be noticed by the same value of Image ID\n",
    "unique_df_2_ad = meta_df_2_ad.drop_duplicates(subset=[\"Image Data ID\"])\n",
    "unique_df_2_mci = meta_df_2_mci.drop_duplicates(subset=[\"Image Data ID\"])\n",
    "unique_df_2_cn = meta_df_2_cn.drop_duplicates(subset=[\"Image Data ID\"])\n",
    "\n",
    "#--For T1, Image ID is not the same value, but subject, sex, age, visit, and acq date\n",
    "unique_df_1_ad = meta_df_1_ad.drop_duplicates(subset=[\"Subject\", \"Sex\", \"Age\", \"Visit\", \"Acq Date\"], keep=\"last\")\n",
    "unique_df_1_mci = meta_df_1_mci.drop_duplicates(subset=[\"Subject\", \"Sex\", \"Age\", \"Visit\", \"Acq Date\"], keep=\"last\")\n",
    "unique_df_1_cn = meta_df_1_cn.drop_duplicates(subset=[\"Subject\", \"Sex\", \"Age\", \"Visit\", \"Acq Date\"], keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 12)\n",
      "(220, 12)\n",
      "(153, 12)\n",
      "(48, 12)\n",
      "(206, 12)\n",
      "(148, 12)\n"
     ]
    }
   ],
   "source": [
    "print(unique_df_2_ad.shape)\n",
    "print(unique_df_2_mci.shape)\n",
    "print(unique_df_2_cn.shape)\n",
    "print(unique_df_1_ad.shape)\n",
    "print(unique_df_1_mci.shape)\n",
    "print(unique_df_1_cn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df_2_ad = unique_df_2_ad.drop(columns=unique_df_2_ad.columns[0], axis=1)\n",
    "unique_df_2_mci = unique_df_2_mci.drop(columns=unique_df_2_mci.columns[0], axis=1)\n",
    "unique_df_2_cn = unique_df_2_cn.drop(columns=unique_df_2_cn.columns[0], axis=1)\n",
    "unique_df_1_ad = unique_df_1_ad.drop(columns=unique_df_1_ad.columns[0], axis=1)\n",
    "unique_df_1_mci = unique_df_1_mci.drop(columns=unique_df_1_mci.columns[0], axis=1)\n",
    "unique_df_1_cn = unique_df_1_cn.drop(columns=unique_df_1_cn.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportCleanCSV(unique_df_2_ad, \"T2\", \"AD\")\n",
    "exportCleanCSV(unique_df_2_mci, \"T2\", \"MCI\")\n",
    "exportCleanCSV(unique_df_2_cn, \"T2\", \"CN\")\n",
    "\n",
    "exportCleanCSV(unique_df_1_ad, \"T1\", \"AD\")\n",
    "exportCleanCSV(unique_df_1_mci, \"T1\", \"MCI\")\n",
    "exportCleanCSV(unique_df_1_cn, \"T1\", \"CN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique and Balanced List of Matched Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dataframe(added_list):\n",
    "    #This function is to add the missed included data because of triple duplicate in T1\n",
    "    meta_dict = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    i=0\n",
    "    for i in range(len(added_list)):\n",
    "        meta_dict[\"Image Data ID\"].append(added_list[i].split(\"__\")[0])\n",
    "        meta_dict[\"Subject\"].append(added_list[i].split(\"__\")[1])\n",
    "        meta_dict[\"Group\"].append(added_list[i].split(\"__\")[2])\n",
    "        meta_dict[\"Sex\"].append(added_list[i].split(\"__\")[3])\n",
    "        meta_dict[\"Age\"].append(added_list[i].split(\"__\")[4])\n",
    "        meta_dict[\"Visit\"].append(added_list[i].split(\"__\")[5])\n",
    "        meta_dict[\"Modality\"].append(added_list[i].split(\"__\")[6])\n",
    "        meta_dict[\"Description\"].append(added_list[i].split(\"__\")[7])\n",
    "        meta_dict[\"Type\"].append(added_list[i].split(\"__\")[8])\n",
    "        meta_dict[\"Acq Date\"].append(added_list[i].split(\"__\")[9])\n",
    "        meta_dict[\"Format\"].append(added_list[i].split(\"__\")[10])\n",
    "\n",
    "        i=i+1\n",
    "        \n",
    "    temp_meta_df = pd.DataFrame(meta_dict)  #convert the dict to a pandas DataFrame    \n",
    "    return temp_meta_df\n",
    "\n",
    "def dropdataframe(df, dropped_list):\n",
    "    i=0\n",
    "    for i in range(len(dropped_list)):\n",
    "        # print(dropped_list[i].split(\"__\")[1])\n",
    "        # temp_meta_df = df[df[\"Image Data ID\"].str.contains(dropped_list[i].split(\"__\")[1])==False]\n",
    "        df = df[df[\"Image Data ID\"].str.contains(dropped_list[i].split(\"__\")[1])==False]\n",
    "        i=i+1\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "Attention: At this moment\n",
    "\n",
    "`add_1_{cond}` represents T1 data that was excluded due to triple duplicates.\n",
    "\n",
    "The list of missed data obtained manually through excel with the filename `Metadata_Matched_Nolimit.xslx` by comparing 3 csv: `Cleaned_Matched_Nolimit` CSV of T1 and T2 from the same group, and `Matched_Nolimit` CSV of T1. The comparison result is stored in section `Duplicated_list`\n",
    "\n",
    "The list of data information is also coppied manually by blocking the whole table and manually change the messy format to array initialization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---------------------------------------\n",
    "# Attention: At this moment\n",
    "# `add_1_{cond}` represents T1 data that was excluded due to triple duplicates.\n",
    "# The list of missed data obtained manually through excel with the filename `Metadata_Matched_Nolimit.xslx` by comparing 3 csv: `Cleaned_Matched_Nolimit` CSV of T1 and T2 from the same group, and `Matched_Nolimit` CSV of T1. The comparison result is stored in section `Duplicated_list`\n",
    "# The list of data information is also coppied manually by blocking the whole table and manually change the messy format to array initialization\n",
    "#---------------------------------------\n",
    "\n",
    "\n",
    "add_1_ad =[\"I29229__127_S_0844__AD__F__85__2__MRI__MP-RAGE REPEAT__Original__11/09/2006__DCM\",\n",
    "\"I46444__130_S_1337__AD__M__72__2__MRI__MPRAGE SENSE repeat__Original__3/22/2007__DCM\"]\n",
    "\n",
    "add_1_cn = [\"I17609__002_S_0559__CN__M__79__2__MRI__MPRAGE SENS__Original__6/27/2006__DCM\",\n",
    "\"I38370__068_S_1191__CN__M__79__2___MRI__ADNI MPRAGE__Original__2/06/2007__DCM\",\n",
    "\"I17176__126_S_0405__CN__M__76__2__MRI__MP-RAGE__Original__6/14/2006__DCM\",\n",
    "\"I17639__126_S_0605__CN__F__76__2__MRI__MP-RAGE__Original__6/29/2006__DCM\",\n",
    "\"I99235__128_S_1242__CN__F__72__4__MRI__MPRAGE Repeat__Original__3/21/2008__DCM\"]\n",
    "\n",
    "drop_2_mci = [\"328__I78109__002_S_0954__MCI__F__70__4__MRI__Double_TSE__Original__10/17/2007__DCM\",\n",
    "\"329__I78110__002_S_0954__MCI__F__70__4__MRI__Double_TSE__Original__10/17/2007__DCM\",\n",
    "\"52__I99903__012_S_1292__MCI__M__77__4__MRI__DUAL_TSEad__Original__3/25/2008__DCM\",\n",
    "\"66__I66877__016_S_1117__MCI__F__70__3__MRI__Axial PD-T2 TSE__Original__8/02/2007__DCM\",\n",
    "\"114__I128637__031_S_1066__MCI__M__75__6__MRI__Axial PD-T2 TSE__Original__11/25/2008__DCM\",\n",
    "\"290__I114314__051_S_1131__MCI__M__88__5__MRI__Axial PD-T2 TSE__Original__7/24/2008__DCM\",\n",
    "\"86__I88901__068_S_0476__MCI__F__78__5__MRI__ADNI Double_TSE__Original__1/22/2008__DCM\",\n",
    "\"87__I88900__068_S_0476__MCI__F__78__5__MRI__ADNI Double_TSE__Original__1/22/2008__DCM\",\n",
    "\"88__I110244__068_S_0476__MCI__F__78__5__MRI__ADNI Double_TSE__Original__1/22/2008__DCM\",\n",
    "\"424__I69857__130_S_0423__MCI__M__81__4__MRI__Double_TSE SENSE__Original__8/20/2007__DCM\",\n",
    "\"426__I39428__130_S_0423__MCI__M__80__3__MRI__Double_TSE SENSE__Original__2/12/2007__DCM\",\n",
    "\"15__I70956__130_S_0449__MCI__F__68__4__MRI__Double_TSE SENSE__Original__8/27/2007__DCM\",\n",
    "\"16__I436758__130_S_0449__MCI__F__68__4__MRI__Double_TSE SENSE__Original__8/27/2007__DCM\",\n",
    "\"102__I54996__131_S_0384__MCI__M__81__4__MRI__Axial PD/T2 FSE__Original__5/22/2007__DCM\"]\n",
    "\n",
    "\n",
    "add_df_1_ad = add2dataframe(add_1_ad)\n",
    "unique_df_1_ad  = unique_df_1_ad.append(add_df_1_ad)\n",
    "# unique_df_1_ad = unique_df_1_ad.drop(columns=unique_df_1_ad.columns[0], axis=1)\n",
    "\n",
    "add_df_1_cn = add2dataframe(add_1_cn)\n",
    "unique_df_1_cn = unique_df_1_cn.append(add_df_1_cn)\n",
    "# unique_df_1_cn = unique_df_1_cn.drop(columns=unique_df_1_cn.columns[0], axis=1)\n",
    "\n",
    "drop_df_2_mci = dropdataframe(unique_df_2_mci, drop_2_mci)\n",
    "# unique_df_2_mci = unique_df_2_mci.drop(columns=unique_df_2_mci.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I78109\n",
      "I78110\n",
      "I99903\n",
      "I66877\n",
      "I128637\n",
      "I114314\n",
      "I88901\n",
      "I88900\n",
      "I110244\n",
      "I69857\n",
      "I39428\n",
      "I70956\n",
      "I436758\n",
      "I54996\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for i in range(len(drop_2_mci)):\n",
    "    print(drop_2_mci[i].split(\"__\")[1])\n",
    "    # temp_meta_df = df[df[\"Image Data ID\"].str.contains(dropped_list[i].split(\"__\")[1])==False]\n",
    "    unique_df_2_mci = unique_df_2_mci[unique_df_2_mci[\"Image Data ID\"].str.contains(drop_2_mci[i].split(\"__\")[1])==False]\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Data ID</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Visit</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Acq Date</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I147843</td>\n",
       "      <td>005_S_0572</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/06/2009</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I89321</td>\n",
       "      <td>005_S_0572</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>2/04/2008</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I115281</td>\n",
       "      <td>005_S_0572</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Axial PD/T2 FSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>8/05/2008</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I20025</td>\n",
       "      <td>005_S_0572</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>MRI</td>\n",
       "      <td>FSE  PD/T2</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/31/2006</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I58877</td>\n",
       "      <td>005_S_0572</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>MRI</td>\n",
       "      <td>FSE  PD/T2</td>\n",
       "      <td>Original</td>\n",
       "      <td>7/09/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>I99400</td>\n",
       "      <td>136_S_0195</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>3/25/2008</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>I46775</td>\n",
       "      <td>136_S_0195</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>3/26/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>I25483</td>\n",
       "      <td>136_S_0195</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>10/02/2006</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>I74927</td>\n",
       "      <td>136_S_0195</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>9/24/2007</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>I140929</td>\n",
       "      <td>136_S_0195</td>\n",
       "      <td>MCI</td>\n",
       "      <td>M</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>MRI</td>\n",
       "      <td>Double_TSE</td>\n",
       "      <td>Original</td>\n",
       "      <td>4/07/2009</td>\n",
       "      <td>DCM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Image Data ID     Subject Group Sex  Age  Visit Modality      Description  \\\n",
       "0         I147843  005_S_0572   MCI   M   82      8      MRI  Axial PD/T2 FSE   \n",
       "1          I89321  005_S_0572   MCI   M   81      5      MRI  Axial PD/T2 FSE   \n",
       "2         I115281  005_S_0572   MCI   M   81      6      MRI  Axial PD/T2 FSE   \n",
       "3          I20025  005_S_0572   MCI   M   79      2      MRI       FSE  PD/T2   \n",
       "4          I58877  005_S_0572   MCI   M   80      4      MRI       FSE  PD/T2   \n",
       "..            ...         ...   ...  ..  ...    ...      ...              ...   \n",
       "452        I99400  136_S_0195   MCI   M   82      6      MRI       Double_TSE   \n",
       "453        I46775  136_S_0195   MCI   M   81      4      MRI       Double_TSE   \n",
       "454        I25483  136_S_0195   MCI   M   80      3      MRI       Double_TSE   \n",
       "455        I74927  136_S_0195   MCI   M   81      5      MRI       Double_TSE   \n",
       "456       I140929  136_S_0195   MCI   M   83      8      MRI       Double_TSE   \n",
       "\n",
       "         Type    Acq Date Format  \n",
       "0    Original   7/06/2009    DCM  \n",
       "1    Original   2/04/2008    DCM  \n",
       "2    Original   8/05/2008    DCM  \n",
       "3    Original   7/31/2006    DCM  \n",
       "4    Original   7/09/2007    DCM  \n",
       "..        ...         ...    ...  \n",
       "452  Original   3/25/2008    DCM  \n",
       "453  Original   3/26/2007    DCM  \n",
       "454  Original  10/02/2006    DCM  \n",
       "455  Original   9/24/2007    DCM  \n",
       "456  Original   4/07/2009    DCM  \n",
       "\n",
       "[206 rows x 11 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df_2_mci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 11)\n",
      "(153, 11)\n",
      "(206, 11)\n"
     ]
    }
   ],
   "source": [
    "print(unique_df_1_ad.shape)\n",
    "print(unique_df_1_cn.shape)\n",
    "print(unique_df_2_mci.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportUniqueCSV(unique_df_2_ad, \"T2\", \"AD\")\n",
    "exportUniqueCSV(unique_df_2_mci, \"T2\", \"MCI\")\n",
    "exportUniqueCSV(unique_df_2_cn, \"T2\", \"CN\")\n",
    "\n",
    "exportUniqueCSV(unique_df_1_ad, \"T1\", \"AD\")\n",
    "exportUniqueCSV(unique_df_1_mci, \"T1\", \"MCI\")\n",
    "exportUniqueCSV(unique_df_1_cn, \"T1\", \"CN\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3,
  "vscode": {
   "interpreter": {
    "hash": "91d5ea55f6078fcf033fd299d4119a7c922feb33f9a1efc7462ec6830a794563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
