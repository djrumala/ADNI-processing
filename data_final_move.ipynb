{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import nibabel as nib\n",
    "# from nibabel.testing import data_path\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt \n",
    "import sys\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def createMetaCombinedString(meta_df):\n",
    "    meta_image = meta_df.loc[:,\"Image Data ID\"]\n",
    "    meta_subject = meta_df.loc[:,\"Subject\"]\n",
    "    meta_visit = meta_df.loc[:,\"Visit\"]\n",
    "\n",
    "    meta_combined= []\n",
    "    i=0\n",
    "    for i in range(len(meta_image)):\n",
    "        # combined = str(meta_subject[i])+\"-\"+str(meta_series[i])+\"-\"+str(meta_image[i])\n",
    "        combined = str(meta_subject[i])+\"-\"+str(meta_image[i]) #to check data availability based on subject and image id\n",
    "        meta_combined.append(combined)\n",
    "        i+=1\n",
    "\n",
    "    return meta_combined\n",
    "\n",
    "def exportCSV(meta_dict, title):\n",
    "    temp_meta_df = pd.DataFrame(meta_dict) #convert dict to dataframe\n",
    "    meta_csv_file = \"./TempMeta/{}.csv\".format(title)\n",
    "    with open(meta_csv_file, mode='w') as f:\n",
    "        temp_meta_df.to_csv(f)\n",
    "\n",
    "    return temp_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "# path = \"C:/Users/Brain-LPDP/Documents/DEWINDA PMDSU/Publication/2023 - Research Visit KHU/Experiment/ADNI1 All Data/ADNI\"\n",
    "# path =\"./ADNI/\"\n",
    "\n",
    "def movePreprocessed(meta_df, path, seq, cond, tesla=3, divider=\"raw_\"):\n",
    "    # target_meta = \"./metadata/\"\n",
    "    target_path = \"./preprocessed/\"\n",
    "    # path = \"./preprocessed_old/{}/{}/\".format(seq, cond)\n",
    "\n",
    "    path = path + \"/{}/{}/\".format(seq, cond)\n",
    "    print(path)\n",
    "    meta_nums = []\n",
    "    result = list(Path(path).glob('**/wm*.nii'))\n",
    "    unique = set(result)\n",
    "    print(\"---------\\n{}w-{}\\nOriginal number of files: {}\\nUnique result:{}\".format(seq, cond, len(result), len(unique)))\n",
    "\n",
    "    sim = 0\n",
    "    # ctr = 0\n",
    "    notsim = 0\n",
    "    j=0\n",
    "    target_dir = os.path.join(target_path, seq)\n",
    "    target_dir = os.path.join(target_dir, cond)\n",
    "\n",
    "    meta_combined = createMetaCombinedString(meta_df)\n",
    "    meta_dict = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict.clear()\n",
    "\n",
    "    meta_dict = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    \n",
    "    notsim = 0\n",
    "    for j in range(len(meta_combined)):\n",
    "\n",
    "        flag = 0 #flag that there is matched data\n",
    "        for f in result[:]:\n",
    "            pathToFile = str(f)\n",
    "            # print(pathToFile)\n",
    "            fileName = pathToFile.split(\"\\\\\")[5] #use \"\\\\\" if \"/\" does not work\n",
    "            # print(fileName)\n",
    "            fileNameNoExt = fileName.split(\".nii\")[0]\n",
    "\n",
    "            part = fileNameNoExt.split('_MR')\n",
    "            id_subject = part[0].split(\"ADNI_\")[1]            \n",
    "            part = part[1].split(divider)[1]\n",
    "            id_series = part.split(\"_S\")[1]\n",
    "            id_series = id_series.split(\"_I\")[0]\n",
    "            id_image = fileNameNoExt.split(\"_I\")[1]\n",
    "        \n",
    "            combinedIDs = id_subject+\"-I\"+id_image\n",
    "            subdirName = id_subject+\"-\"+id_series+\"-\"+id_image\n",
    "            \n",
    "            \n",
    "            if combinedIDs in meta_combined[j]: #Files already preprocessed             \n",
    "                isExist = os.path.exists(target_dir)    \n",
    "\n",
    "                if isExist == False:\n",
    "                    os.mkdir(target_dir)\n",
    "                \n",
    "                shutil.copy(f,target_dir+\"/{}-\".format(j)+fileName)\n",
    "                \n",
    "                flag = 1\n",
    "\n",
    "        if flag==1: #Files are preprocessed\n",
    "            sim+=1      \n",
    "\n",
    "        else: #Listing the not-yet-preprocessed files\n",
    "            meta_dict[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "            meta_dict[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "            meta_dict[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "            meta_dict[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "            meta_dict[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "            meta_dict[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "            meta_dict[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "            meta_dict[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "            meta_dict[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "            meta_dict[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "            meta_dict[\"Format\"].append( meta_df.loc[j,\"Format\"])   \n",
    "            meta_nums.append(j)\n",
    "            notsim +=1          \n",
    "                \n",
    "        j+=1\n",
    "    # ctr+=1   \n",
    "    # print(ctr)\n",
    "    print(\"Total {}w-{} data is {} and not sim is {}\".format(seq, cond, sim, notsim))\n",
    "    return meta_dict, meta_nums\n",
    "\n",
    "def move2preprocess(meta_df, seq, cond, tesla=3, divider=\"raw_\"):\n",
    "    nii_path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "\n",
    "    target_meta = \"./TempMeta/\"\n",
    "    target_path = \"./TempData/\"\n",
    "\n",
    "    result = sorted(list(Path(nii_path).glob('**/wm*.nii')))\n",
    "    unique = set(result)\n",
    "    print(\"---------\\n{}w-{}\\nOriginal number: {}\\nUnique result:{}\".format(seq, cond, len(result), len(unique)))\n",
    "\n",
    "    sim = 0\n",
    "    ctr = 0\n",
    "    meta_combined = createMetaCombinedString(meta_df)\n",
    "\n",
    "    for f in result[:]:\n",
    "        pathToFile = str(f)\n",
    "        fileName = pathToFile.split(\"/\")[7] #use \"\\\\\" if \"/\" does not work 7 if from folder 3T/seq/group\n",
    "        fileNameNoExt = fileName.split(\".nii\")[0]\n",
    "        \n",
    "        part = fileNameNoExt.split('_MR')\n",
    "        id_subject = part[0].split(\"ADNI_\")[1]\n",
    "        part = part[1].split(divider)[1]\n",
    "        id_series = part.split(\"_S\")[1]\n",
    "        id_series = id_series.split(\"_I\")[0]\n",
    "        id_image = fileNameNoExt.split(\"_I\")[1]\n",
    "    \n",
    "        combinedIDs = id_subject+\"-I\"+id_image\n",
    "        subdirName = id_subject+\"-\"+id_series+\"-\"+id_image\n",
    "        \n",
    "        target_dir = os.path.join(target_path, seq)\n",
    "        target_dir = os.path.join(target_dir, cond)\n",
    "        target_dir = os.path.join(target_dir, subdirName)\n",
    "        isExist = os.path.exists(target_dir)    \n",
    "\n",
    "        j = 0\n",
    "        for j in range(len(meta_combined)):\n",
    "            if meta_combined[j] in combinedIDs:\n",
    "\n",
    "                if isExist == False:\n",
    "                    os.mkdir(target_dir)\n",
    "                # print(target_dir)\n",
    "                # print(\"File {} copied to target folder\".format(fileName))\n",
    "                shutil.copy(f,target_dir+\"/\"+fileName)\n",
    "\n",
    "                sim+=1\n",
    "            j+=1\n",
    "        ctr+=1    \n",
    "        # print(\"File {}\".format(ctr))\n",
    "    print(\"Total {}w - {} data is {}\".format(seq, cond, sim))\n",
    "\n",
    "def freemove(path, seq, cond, tesla=3): #move anything based on filename\n",
    "    # target_meta = \"./metadata/\"\n",
    "    target_path = \"./arnold/\"\n",
    "    # path = \"./preprocessed_old/{}/{}/\".format(seq, cond)\n",
    "    target_dir = os.path.join(target_path, seq)\n",
    "    target_dir = os.path.join(target_dir, cond)\n",
    "\n",
    "    path = path + \"/{}/{}/\".format(seq, cond)\n",
    "   \n",
    "    meta_nums = []\n",
    "    result = sorted(list(Path(path).glob('**/*.nii'))) #modify it to catch certain chars\n",
    "    unique = set(result)\n",
    "    print(\"---------\\n{}w-{}\\nOriginal number of files: {}\\nUnique result:{}\".format(seq, cond, len(result), len(unique)))\n",
    "    \n",
    "    j =0\n",
    "    for f in result[:]:\n",
    "        pathToFile = str(f)\n",
    "        # print(pathToFile)\n",
    "        fileName = pathToFile.split(\"\\\\\")[4] #use \"\\\\\" if \"/\" does not work\n",
    "        # print(fileName)\n",
    "        \n",
    "        # if \"wm\" not in fileName and \"y_\" not in fileName and \"mwp\" not in fileName and \"p0\" not in fileName: #Files already preprocessed             \n",
    "        if \"ADNI\" in fileName:\n",
    "            print(fileName)\n",
    "            isExist = os.path.exists(target_dir)    \n",
    "\n",
    "            if isExist == False:\n",
    "                os.mkdir(target_dir)\n",
    "            \n",
    "            shutil.copy(f,target_dir+\"/{}-\".format(j)+fileName)\n",
    "            j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freemove(\"./preprocessed/\", \"T2\", \"AD\")\n",
    "freemove(\"./preprocessed\", \"T2\", \"MCI\")\n",
    "freemove(\"./preprocessed/\", \"T2\", \"CN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Already Preprocessed Files\n",
    "------\n",
    "Moving already prerpocessed files from the source (previous preprocessed folder) to the target folder and keep the list of the image that is not yet preprocessed\n",
    "\n",
    "**Current Steps:**\n",
    "1. Preprocessed files are taken from the folder `/preprocess_old` and saved to `/preprocessed` \n",
    "<br><br>-The preprocessed files are saved with this filename: `/preprocessed/{meta_id}_{filename}.nii.gz`\n",
    "<br>-`{meta_id}` is the serial number of the file shown in the csv list\n",
    "<br>-The idea of giving `{meta_id}` is to handle pairing of T1 and T2 data together\n",
    "\n",
    "\n",
    "2. The list of not yet preprocessed files is saved as `TempMeta/To-Be-Preprocessed_{seq}w_{group}.csv`\n",
    "-----\n",
    "**Further steps:**\n",
    "The list in Step #2 will be used to move the to-be-prerprocessed files to folder \"/TempData\" <br> This way the files can be transferred to the windows computer to be preprocessed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Old Preprocessed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesla = 3 #1.5 or 3\n",
    "# downloadDate = \"12_05_2022\"\n",
    "# path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "\n",
    "# path = \"./preprocessed_old/{}/{}/\".format(seq, cond)\n",
    "\n",
    "seq = \"T1\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_1_ad = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_1_mci = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_1_cn =  \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "seq = \"T2\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_2_ad = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_2_mci =  \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_2_cn = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "# path = \"./data/{}/{}/\".format(seq, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df_1_ad = pd.read_csv(meta_path_1_ad, delimiter=',')\n",
    "meta_df_1_mci = pd.read_csv(meta_path_1_mci, delimiter=',')\n",
    "meta_df_1_cn = pd.read_csv(meta_path_1_cn, delimiter=',')\n",
    "meta_df_2_ad = pd.read_csv(meta_path_2_ad, delimiter=',')\n",
    "meta_df_2_mci = pd.read_csv(meta_path_2_mci, delimiter=',')\n",
    "meta_df_2_cn = pd.read_csv(meta_path_2_cn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"./preprocessed/\"\n",
    "path = \"./preprocessed_old\"\n",
    "\n",
    "dict_1_ad, meta_num_1_ad = movePreprocessed(meta_df_1_ad, path, \"T1\", \"AD\")\n",
    "dict_1_mci, meta_num_1_mci = movePreprocessed(meta_df_1_mci, path, \"T1\", \"MCI\")\n",
    "dict_1_cn, meta_num_1_cn = movePreprocessed(meta_df_1_cn, path, \"T1\", \"CN\")\n",
    "dict_2_ad, meta_num_2_ad = movePreprocessed(meta_df_2_ad, path,  \"T2\", \"AD\")\n",
    "dict_2_mci, meta_num_2_mci = movePreprocessed(meta_df_2_mci, path, \"T2\", \"MCI\")\n",
    "dict_2_cn, meta_num_2_cn = movePreprocessed(meta_df_2_cn, path,  \"T2\", \"CN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(meta_num_1_ad)\n",
    "print(meta_num_1_mci)\n",
    "print(meta_num_1_cn)\n",
    "print(meta_num_2_ad)\n",
    "print(meta_num_2_mci)\n",
    "print(meta_num_2_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobe_df_1_ad = exportCSV(dict_1_ad, title=\"To-Be-Preprocessed_{}w_{}\".format(\"T1\", \"AD\"))\n",
    "tobe_df_1_mci = exportCSV(dict_1_mci, title=\"To-Be-Preprocessed_{}w_{}\".format(\"T1\", \"MCI\"))\n",
    "tobe_df_1_cn = exportCSV(dict_1_cn, title=\"To-Be-Preprocessed_{}w_{}\".format(\"T1\", \"CN\"))\n",
    "tobe_df_2_ad = exportCSV(dict_2_ad, title=\"To-Be-Preprocessed_{}w_{}\".format(\"T2\", \"AD\"))\n",
    "tobe_df_2_mci = exportCSV(dict_2_mci, title=\"To-Be-Preprocessed_{}w_{}\".format(\"T2\", \"MCI\"))\n",
    "tobe_df_2_cn = exportCSV(dict_2_cn, title=\"To-Be-Preprocessed_{}w_{}\".format(\"T2\", \"CN\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Additional Preprocessed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesla = 3 #1.5 or 3\n",
    "# downloadDate = \"12_05_2022\"\n",
    "# path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "\n",
    "path = \"./preprocessed_addition/{}/{}/\".format(seq, cond)\n",
    "\n",
    "seq = \"T1\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_1_ad = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_1_mci = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_1_cn =  \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "seq = \"T2\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_2_ad = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_2_mci =  \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_2_cn = \"./TempMeta/Balanced_Meta_{}w_{}.csv\".format(seq, cond)\n",
    "# path = \"./data/{}/{}/\".format(seq, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df_1_ad = pd.read_csv(meta_path_1_ad, delimiter=',')\n",
    "meta_df_1_mci = pd.read_csv(meta_path_1_mci, delimiter=',')\n",
    "meta_df_1_cn = pd.read_csv(meta_path_1_cn, delimiter=',')\n",
    "meta_df_2_ad = pd.read_csv(meta_path_2_ad, delimiter=',')\n",
    "meta_df_2_mci = pd.read_csv(meta_path_2_mci, delimiter=',')\n",
    "meta_df_2_cn = pd.read_csv(meta_path_2_cn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"./preprocessed/\"\n",
    "path = \"./TempData\"\n",
    "\n",
    "# dict_1_ad, meta_num_1_ad = movePreprocessed(meta_df_1_ad, path, \"T1\", \"AD\")\n",
    "dict_1_mci, meta_num_1_mci = movePreprocessed(meta_df_1_mci, path, \"T1\", \"MCI\")\n",
    "dict_1_cn, meta_num_1_cn = movePreprocessed(meta_df_1_cn, path, \"T1\", \"CN\")\n",
    "# dict_2_ad, meta_num_2_ad = movePreprocessed(meta_df_2_ad, path,  \"T2\", \"AD\")\n",
    "# dict_2_mci, meta_num_2_mci = movePreprocessed(meta_df_2_mci, path, \"T2\", \"MCI\")\n",
    "# dict_2_cn, meta_num_2_cn = movePreprocessed(meta_df_2_cn, path,  \"T2\", \"CN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Files to be Preprocessed\n",
    "\n",
    "----\n",
    "Moving files that are not yet preprocessed to the target folder, based on the list stored in metadata generated from the previous step. \n",
    "\n",
    "**Current Steps:**\n",
    "1. The not yet preprocessed files re taken from the original downloaded folder `/3T/` and saved to `/TempData/` \n",
    "<br><br>-The files are saved with this filename: `/TempMeta/{filename}.nii.gz`\n",
    "\n",
    "2. The data will be preprocessed in windows PC using MATLAB, therefore need to be put inside a decent sub-directory that contains `{subject id}-{series id}-{image id}`\n",
    "-----\n",
    "**Further steps:**\n",
    " After the data get preprocessed, we can go on with the third section that can be performed using the functions and algorithms in the first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = 3 #1.5 or 3\n",
    "# downloadDate = \"12_05_2022\"\n",
    "path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "# path = \"./preprocessed_old/{}/{}/\".format(seq, cond)\n",
    "\n",
    "seq = \"T1\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_1_ad = \"./TempMeta/To-Be-Preprocessed_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_1_mci = \"./TempMeta/To-Be-Preprocessed_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_1_cn = \"./TempMeta/To-Be-Preprocessed_{}w_{}.csv\".format(seq, cond)\n",
    "seq = \"T2\"\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_2_ad = \"./TempMeta/To-Be-Preprocessed_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_2_mci = \"./TempMeta/To-Be-Preprocessed_{}w_{}.csv\".format(seq, cond)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_2_cn = \"./TempMeta/To-Be-Preprocessed_{}w_{}.csv\".format(seq, cond)\n",
    "# path = \"./data/{}/{}/\".format(seq, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df_1_ad = pd.read_csv(meta_path_1_ad, delimiter=',')\n",
    "meta_df_1_mci = pd.read_csv(meta_path_1_mci, delimiter=',')\n",
    "meta_df_1_cn = pd.read_csv(meta_path_1_cn, delimiter=',')\n",
    "meta_df_2_ad = pd.read_csv(meta_path_2_ad, delimiter=',')\n",
    "meta_df_2_mci = pd.read_csv(meta_path_2_mci, delimiter=',')\n",
    "meta_df_2_cn = pd.read_csv(meta_path_2_cn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move2preprocess(meta_df_1_ad, \"T1\", \"AD\")\n",
    "move2preprocess(meta_df_1_mci, \"T1\", \"MCI\")\n",
    "move2preprocess(meta_df_1_cn, \"T1\", \"CN\")\n",
    "# move2preprocess(meta_df_2_ad, \"T2\", \"AD\")\n",
    "# move2preprocess(meta_df_2_mci, \"T2\", \"MCI\")\n",
    "# move2preprocess(meta_df_2_cn, \"T2\", \"CN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Separation For Robustness Evaluation\n",
    "\n",
    "The idea is to move the new datasets (hold-out data) for robustness evaluation to be preprocessed.\n",
    "The hold-out datasets include 3T and 1.5T MRI. Hold-out data has never been used as the training data (the initial 5-fold data) --refer to `Balanced_Meta_{seq}w_{group}` for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "# path = \"C:/Users/Brain-LPDP/Documents/DEWINDA PMDSU/Publication/2023 - Research Visit KHU/Experiment/ADNI1 All Data/ADNI\"\n",
    "# path =\"./ADNI/\"\n",
    "\n",
    "def find2separate(meta_df, ref_df, seq, tesla=3):\n",
    "    nii_path = \"./DataOri/{}T/{}/\".format(tesla, seq)\n",
    "\n",
    "    result = sorted(list(Path(nii_path).glob('**/*.nii')))\n",
    "    unique = set(result)\n",
    "    print(\"---------\\n{}w\\nOriginal number: {}\\nUnique result:{}\".format(seq, len(result), len(unique)))\n",
    "\n",
    "    sim = 0\n",
    "    notsim = 0\n",
    "    ctr = 0\n",
    "    meta_combined = createMetaCombinedString(meta_df)\n",
    "    ref_combined = createMetaCombinedString(ref_df)\n",
    "\n",
    "    meta_dict_ad = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_ad.clear()\n",
    "    meta_dict_mci = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_mci.clear()\n",
    "    meta_dict_cn = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_cn.clear()\n",
    "    \n",
    "    meta_dict_ad = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_mci = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_cn = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    \n",
    "    #Prepared array to be exported to CSV (separated per class)\n",
    "    meta_nums_ad = []\n",
    "    meta_nums_mci = []\n",
    "    meta_nums_cn = []\n",
    "\n",
    "    #Loop to check if there is already used data\n",
    "    for j in range(len(meta_combined)):\n",
    "        flag = 0 #flag that there is matched data\n",
    "\n",
    "        for k in range(len(ref_combined)):\n",
    "\n",
    "            # if ref_combined[k] in meta_combined[j]: #Similarities based on subject and imageid\n",
    "            if meta_df.loc[j,\"Subject\"] in ref_df.loc[k,\"Subject\"]:  #similarities based on subject id only\n",
    "                print(\"{} and {}\".format(meta_combined[j], ref_combined[k]))\n",
    "                flag = 1\n",
    "\n",
    "        if flag==1: #Files are already used\n",
    "            print(\"flag\")\n",
    "            sim = sim + 1    \n",
    "\n",
    "        else: #Listing the not-yet-used files to be preprocessed\n",
    "            if \"AD\" in meta_df.loc[j,\"Group\"]:\n",
    "                meta_dict_ad[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "                meta_dict_ad[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "                meta_dict_ad[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "                meta_dict_ad[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "                meta_dict_ad[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "                meta_dict_ad[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "                meta_dict_ad[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "                meta_dict_ad[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "                meta_dict_ad[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "                meta_dict_ad[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "                meta_dict_ad[\"Format\"].append( meta_df.loc[j,\"Format\"])\n",
    "\n",
    "            elif \"MCI\" in meta_df.loc[j,\"Group\"]:\n",
    "                meta_dict_mci[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "                meta_dict_mci[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "                meta_dict_mci[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "                meta_dict_mci[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "                meta_dict_mci[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "                meta_dict_mci[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "                meta_dict_mci[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "                meta_dict_mci[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "                meta_dict_mci[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "                meta_dict_mci[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "                meta_dict_mci[\"Format\"].append( meta_df.loc[j,\"Format\"])\n",
    "            else:\n",
    "                meta_dict_cn[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "                meta_dict_cn[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "                meta_dict_cn[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "                meta_dict_cn[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "                meta_dict_cn[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "                meta_dict_cn[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "                meta_dict_cn[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "                meta_dict_cn[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "                meta_dict_cn[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "                meta_dict_cn[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "                meta_dict_cn[\"Format\"].append( meta_df.loc[j,\"Format\"]) \n",
    "\n",
    "            notsim +=1          \n",
    "        j+=1\n",
    "        \n",
    "    print(\"Total of used {}w data is {}\".format(seq, sim))\n",
    "    return meta_dict_ad, meta_dict_mci, meta_dict_cn\n",
    "\n",
    "def move2separate(meta_df, seq, tesla=3, ONLY_BASELINE=False, divider=\"Br_\"):\n",
    "    nii_path = \"./DataOri/{}T/{}/\".format(tesla, seq)\n",
    "    target_path = \"./DataSep/\"\n",
    "\n",
    "    tesla = str(tesla) + \"T\"\n",
    "    result = sorted(list(Path(nii_path).glob('**/*.nii')))\n",
    "    unique = set(result)\n",
    "    print(\"---------\\n{}w\\nOriginal number: {}\\nUnique result:{}\".format(seq, len(result), len(unique)))\n",
    "\n",
    "    sim = 0\n",
    "    ctr = 0\n",
    "    meta_combined = createMetaCombinedString(meta_df)\n",
    "\n",
    "    #Initialize dict to save metadata\n",
    "    meta_dict_ad = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_mci = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "    meta_dict_cn = {\"Image Data ID\" : [], \"Subject\":[], \"Group\":[],\"Sex\":[],\"Age\":[],\"Visit\":[],\"Modality\":[],\"Description\":[],\"Type\":[],\"Acq Date\":[],\"Format\":[]}\n",
    "\n",
    "    for f in result[:]:\n",
    "        pathToFile = str(f)\n",
    "        #print(pathToFile)\n",
    "        fileName = pathToFile.split(\"\\\\\")[7] #use \"\\\\\" if \"/\" does not work 7 if from folder 3T/seq/group\n",
    "        fileNameNoExt = fileName.split(\".nii\")[0]\n",
    "        #print(fileNameNoExt)\n",
    "        part = fileNameNoExt.split('_MR')\n",
    "        id_subject = part[0].split(\"ADNI_\")[1]\n",
    "        part = part[1].split(divider)[1] #raw if T2, Br if T1?\n",
    "        id_series = part.split(\"_S\")[1]\n",
    "        id_series = id_series.split(\"_I\")[0]\n",
    "        id_image = fileNameNoExt.split(\"_I\")[1]\n",
    "    \n",
    "        combinedIDs = id_subject+\"-I\"+id_image\n",
    "        subdirName = id_subject+\"-\"+id_series+\"-\"+id_image\n",
    "        \n",
    "        j = 0\n",
    "        for j in range(len(meta_combined)):\n",
    "            flag = 0\n",
    "            if meta_combined[j] in combinedIDs:\n",
    "                target_dir = os.path.join(target_path, tesla)\n",
    "                target_dir = os.path.join(target_dir, meta_df.loc[j,\"Group\"])\n",
    "                target_dir = os.path.join(target_dir, subdirName)\n",
    "                \n",
    "                isExist = os.path.exists(target_dir)\n",
    "                \n",
    "                if ONLY_BASELINE: #adjust the conditions\n",
    "                    # if \"AD\" in meta_df.loc[j, \"Group\"]:\n",
    "                    if \"sc\" in meta_df.loc[j, \"Visit\"] and \"MPR-R\" not in meta_df.loc[j, \"Description\"]: #Take only screening for 15T MRI\n",
    "                    # if \"bl\" in meta_df.loc[j, \"Visit\"] or \"m06\" in meta_df.loc[j, \"Visit\"] or \"m12\" in meta_df.loc[j, \"Visit\"]: #Take only baseline from MCI and CN\n",
    "                        if isExist == False:\n",
    "                            os.mkdir(target_dir)\n",
    "                        # print(target_dir)\n",
    "                        print(\"File {} copied to target folder\".format(fileName))\n",
    "                        shutil.copy(f,target_dir+\"/\"+fileName)\n",
    "                        flag=1\n",
    "                else:\n",
    "                    if isExist == False:\n",
    "                        os.mkdir(target_dir)\n",
    "                    # print(target_dir)\n",
    "                    print(\"File {} copied to target folder\".format(fileName))\n",
    "                    shutil.copy(f,target_dir+\"/\"+fileName)\n",
    "                    flag=1    \n",
    "                sim+=1\n",
    "            \n",
    "            if flag==1: #Files are already used\n",
    "                if \"AD\" in meta_df.loc[j,\"Group\"]:\n",
    "                    meta_dict_ad[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "                    meta_dict_ad[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "                    meta_dict_ad[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "                    meta_dict_ad[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "                    meta_dict_ad[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "                    meta_dict_ad[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "                    meta_dict_ad[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "                    meta_dict_ad[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "                    meta_dict_ad[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "                    meta_dict_ad[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "                    meta_dict_ad[\"Format\"].append( meta_df.loc[j,\"Format\"])   \n",
    "                    \n",
    "                elif \"MCI\" in meta_df.loc[j,\"Group\"]:\n",
    "                    meta_dict_mci[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "                    meta_dict_mci[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "                    meta_dict_mci[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "                    meta_dict_mci[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "                    meta_dict_mci[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "                    meta_dict_mci[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "                    meta_dict_mci[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "                    meta_dict_mci[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "                    meta_dict_mci[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "                    meta_dict_mci[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "                    meta_dict_mci[\"Format\"].append( meta_df.loc[j,\"Format\"])   \n",
    "                    \n",
    "                else:\n",
    "                    meta_dict_cn[\"Image Data ID\"].append(meta_df.loc[j,\"Image Data ID\"])\n",
    "                    meta_dict_cn[\"Subject\"].append(meta_df.loc[j,\"Subject\"])\n",
    "                    meta_dict_cn[\"Group\"].append(meta_df.loc[j,\"Group\"])\n",
    "                    meta_dict_cn[\"Sex\"].append(meta_df.loc[j,\"Sex\"])\n",
    "                    meta_dict_cn[\"Age\"].append(meta_df.loc[j,\"Age\"])\n",
    "                    meta_dict_cn[\"Visit\"].append(meta_df.loc[j,\"Visit\"])\n",
    "                    meta_dict_cn[\"Modality\"].append(meta_df.loc[j,\"Modality\"])\n",
    "                    meta_dict_cn[\"Description\"].append(meta_df.loc[j,\"Description\"])\n",
    "                    meta_dict_cn[\"Type\"].append(meta_df.loc[j,\"Type\"])\n",
    "                    meta_dict_cn[\"Acq Date\"].append(meta_df.loc[j,\"Acq Date\"])\n",
    "                    meta_dict_cn[\"Format\"].append( meta_df.loc[j,\"Format\"])   \n",
    "                \n",
    "            j+=1\n",
    "            \n",
    "    print(\"Total {}w data moved is {}\".format(seq, sim))\n",
    "    return meta_dict_ad, meta_dict_mci, meta_dict_cn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Already Used Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla = 15\n",
    "\n",
    "# meta_path = \"./Metadata/ADNI1_Baseline_3T_6_08_2023.csv\" #Meta path for the target data\n",
    "# meta_path = \"./Metadata/ADNI1_Complete_3Yr_3T_6_08_2023.csv\"\n",
    "meta_path = \"./Metadata/ADNI1_Complete_1Yr_15T_6_08_2023.csv\"\n",
    "\n",
    "# Reference metadata (Already used for training)\n",
    "meta_ad = \"./Metadata/Balanced_Meta_T1w_AD.csv\"\n",
    "meta_mci = \"./Metadata/Balanced_Meta_T1w_MCI.csv\"\n",
    "meta_cn = \"./Metadata/Balanced_Meta_T1w_CN.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df = pd.read_csv(meta_path, delimiter=',')\n",
    "meta_df_ad = pd.read_csv(meta_ad, delimiter=',')\n",
    "meta_df_mci = pd.read_csv(meta_mci, delimiter=',')\n",
    "meta_df_cn = pd.read_csv(meta_cn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([meta_df_ad, meta_df_mci, meta_df_cn], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1_ad, dict_1_mci, dict_1_cn = find2separate(meta_df,combined_df, \"T1\", Tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobe_df_1_ad = exportCSV(dict_1_ad, title=\"HoldOut_{}w_{}_{}T\".format(\"T1\", \"AD\", Tesla))\n",
    "tobe_df_1_mci = exportCSV(dict_1_mci, title=\"HoldOut_{}w_{}_{}T\".format(\"T1\", \"MCI\", Tesla))\n",
    "tobe_df_1_cn = exportCSV(dict_1_cn, title=\"HoldOut_{}w_{}_{}T\".format(\"T1\", \"CN\", Tesla))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move New Data To Be Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tesla = 15\n",
    "\n",
    "# meta_path = \"./Metadata/ADNI1_Baseline_3T_6_08_2023.csv\" #Meta path for the target data\n",
    "# meta_path = \"./Metadata/ADNI1_Complete_3Yr_3T_6_08_2023.csv\"\n",
    "meta_path = \"./Metadata/ADNI1_Complete_1Yr_15T_6_08_2023.csv\"\n",
    "\n",
    "# Reference metadata (Already used for training)\n",
    "meta_ad = \"./TempMeta/HoldOut_T1w_AD_{}T.csv\".format(Tesla)\n",
    "meta_mci = \"./TempMeta/HoldOut_T1w_MCI_{}T.csv\".format(Tesla)\n",
    "meta_cn = \"./TempMeta/HoldOut_T1w_CN_{}T.csv\".format(Tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df = pd.read_csv(meta_path, delimiter=',')\n",
    "meta_df_ad = pd.read_csv(meta_ad, delimiter=',')\n",
    "meta_df_mci = pd.read_csv(meta_mci, delimiter=',')\n",
    "meta_df_cn = pd.read_csv(meta_cn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([meta_df_ad, meta_df_mci, meta_df_cn], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1_ad, dict_1_mci, dict_1_cn = move2separate(combined_df, \"T1\", Tesla, ONLY_BASELINE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobe_df_1_ad = exportCSV(dict_1_ad, title=\"HoldOut_Cleaned_{}w_{}_{}T\".format(\"T1\", \"AD\", Tesla))\n",
    "tobe_df_1_mci = exportCSV(dict_1_mci, title=\"HoldOut_Cleaned_{}w_{}_{}T\".format(\"T1\", \"MCI\", Tesla))\n",
    "tobe_df_1_cn = exportCSV(dict_1_cn, title=\"HoldOut_Cleaned_{}w_{}_{}T\".format(\"T1\", \"CN\", Tesla))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Preprocessed Hold-out Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tesla = 3 #1.5 or 3\n",
    "# downloadDate = \"12_05_2022\"\n",
    "# path = \"./{}T/{}/{}/\".format(tesla, seq, cond)\n",
    "\n",
    "# path = \"./preprocessed_old/{}/{}/\".format(seq, cond)\n",
    "\n",
    "seq = \"T1\"\n",
    "Tesla = 15\n",
    "cond= \"AD\" #condition is AD or CN or MCI\n",
    "meta_path_1_ad = \"./TempMeta/HoldOut_Balanced_{}w_{}_{}T.csv\".format(seq, cond, Tesla)\n",
    "cond= \"MCI\" #condition is AD or CN or MCI\n",
    "meta_path_1_mci = \"./TempMeta/HoldOut_Balanced_{}w_{}_{}T.csv\".format(seq, cond, Tesla)\n",
    "cond= \"CN\" #condition is AD or CN or MCI\n",
    "meta_path_1_cn = \"./TempMeta/HoldOut_Balanced_{}w_{}_{}T.csv\".format(seq, cond, Tesla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "# meta_path = \"./Metadata/metadata_final.csv\"\n",
    "meta_df_1_ad = pd.read_csv(meta_path_1_ad, delimiter=',')\n",
    "meta_df_1_mci = pd.read_csv(meta_path_1_mci, delimiter=',')\n",
    "meta_df_1_cn = pd.read_csv(meta_path_1_cn, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"./preprocessed/\"\n",
    "path = \"./TempData\"\n",
    "\n",
    "dict_1_ad, meta_num_1_ad = movePreprocessed(meta_df_1_ad, path, \"15T\", \"AD\", divider=\"Br_\")\n",
    "dict_1_mci, meta_num_1_mci = movePreprocessed(meta_df_1_mci, path, \"15T\", \"MCI\", divider=\"Br_\")\n",
    "dict_1_cn, meta_num_1_cn = movePreprocessed(meta_df_1_cn, path, \"15T\", \"CN\", divider=\"Br_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
