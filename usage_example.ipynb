{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03295835",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# Add project to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import from libs\n",
    "from libs.file_operations import (\n",
    "    movePreprocessed,\n",
    "    freemove,\n",
    "    move2preprocess,\n",
    "    move2convert,\n",
    "    moveConverted,\n",
    ")\n",
    "from libs.metadata import (\n",
    "    createMetaCombinedString,\n",
    "    exportCSV,\n",
    "    filterMetadata,\n",
    ")\n",
    "from libs.utils import (\n",
    "    validate_directory_structure,\n",
    "    ensure_output_directories,\n",
    "    print_pipeline_status,\n",
    "    list_available_metadata,\n",
    "    get_directory_summary,\n",
    ")\n",
    "from libs.config import (\n",
    "    BASE_DIR,\n",
    "    SEQUENCES,\n",
    "    CONDITIONS,\n",
    "    TEMP_META_DIR,\n",
    ")\n",
    "\n",
    "print(\"âœ“ All imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f70db4b",
   "metadata": {},
   "source": [
    "## 2. Pre-flight Check\n",
    "\n",
    "Verify that your ADNI data directory structure is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "ensure_output_directories(str(BASE_DIR))\n",
    "print(\"\\nâœ“ Output directories ensured!\\n\")\n",
    "\n",
    "# Validate directory structure\n",
    "validation = validate_directory_structure(str(BASE_DIR))\n",
    "print(\"Directory Structure Validation:\")\n",
    "for name, exists in validation.items():\n",
    "    status = \"âœ“\" if exists else \"âœ—\"\n",
    "    print(f\"  {status} {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3853a",
   "metadata": {},
   "source": [
    "## 3. Pipeline Status Dashboard\n",
    "\n",
    "Check current state of all data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a4f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "summary = get_directory_summary(str(BASE_DIR))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADNI Pipeline Status\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFile Counts by Directory:\")\n",
    "for name, count in summary.items():\n",
    "    print(f\"  {name}: {count}\")\n",
    "\n",
    "# Available metadata\n",
    "meta_files = list_available_metadata(str(TEMP_META_DIR))\n",
    "print(\"\\nAvailable Metadata Files:\")\n",
    "if meta_files:\n",
    "    for f in meta_files:\n",
    "        print(f\"  â€¢ {f}\")\n",
    "else:\n",
    "    print(\"  (No metadata files found)\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3de7da",
   "metadata": {},
   "source": [
    "## 4. Load Metadata\n",
    "\n",
    "Select and load metadata CSV file for your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752db1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available metadata files\n",
    "available_meta = list_available_metadata(str(TEMP_META_DIR))\n",
    "\n",
    "if not available_meta:\n",
    "    print(\"âš  No metadata files found!\")\n",
    "    print(f\"\\nPlace your metadata CSV files in: {TEMP_META_DIR}\")\n",
    "    print(\"\\nExpected columns:\")\n",
    "    print(\"  Image Data ID, Subject, Group, Sex, Age, Visit, Modality, Description, Type, Acq Date, Format\")\n",
    "else:\n",
    "    # Create dropdown for metadata selection\n",
    "    meta_dropdown = widgets.Dropdown(\n",
    "        options=available_meta,\n",
    "        description='Metadata File:',\n",
    "        style={'description_width': '120px'}\n",
    "    )\n",
    "    \n",
    "    load_button = widgets.Button(description='Load Metadata', button_style='info')\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_load_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            try:\n",
    "                meta_path = TEMP_META_DIR / meta_dropdown.value\n",
    "                global meta_df\n",
    "                meta_df = pd.read_csv(meta_path)\n",
    "                print(f\"âœ“ Loaded: {meta_dropdown.value}\")\n",
    "                print(f\"  Shape: {meta_df.shape}\")\n",
    "                print(f\"\\nFirst few rows:\")\n",
    "                display(meta_df.head())\n",
    "            except Exception as e:\n",
    "                print(f\"âœ— Error loading metadata: {e}\")\n",
    "    \n",
    "    load_button.on_click(on_load_clicked)\n",
    "    \n",
    "    display(widgets.HBox([meta_dropdown, load_button]))\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98c46c",
   "metadata": {},
   "source": [
    "## 5. Interactive Parameter Selection\n",
    "\n",
    "Choose workflow parameters using dropdowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10943b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive parameter selectors\n",
    "seq_widget = widgets.Dropdown(\n",
    "    options=SEQUENCES,\n",
    "    description='Sequence:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "cond_widget = widgets.Dropdown(\n",
    "    options=CONDITIONS,\n",
    "    description='Condition:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "tesla_widget = widgets.RadioButtons(\n",
    "    options=[1.5, 3],\n",
    "    description='Tesla:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "divider_widget = widgets.Dropdown(\n",
    "    options={'raw_': 'raw_', 'br_': 'br_', 'Br_': 'Br_'},\n",
    "    description='Divider:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "print(\"Select Parameters:\")\n",
    "print()\n",
    "display(seq_widget)\n",
    "display(cond_widget)\n",
    "display(tesla_widget)\n",
    "display(divider_widget)\n",
    "\n",
    "print(\"\\nCurrent Selection:\")\n",
    "print(f\"  Sequence: {seq_widget.value}\")\n",
    "print(f\"  Condition: {cond_widget.value}\")\n",
    "print(f\"  Tesla: {tesla_widget.value}\")\n",
    "print(f\"  Divider: {divider_widget.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084edee",
   "metadata": {},
   "source": [
    "## 6. Workflow Selection\n",
    "\n",
    "Choose which pipeline step to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77683edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_widget = widgets.ToggleButtons(\n",
    "    options={\n",
    "        'Move Preprocessed': 'move_preprocessed',\n",
    "        'Move to Preprocess': 'move2preprocess',\n",
    "        'Move to Convert': 'move2convert',\n",
    "        'Move Converted': 'moveConverted',\n",
    "        'Free Move': 'freemove',\n",
    "    },\n",
    "    description='Workflow:',\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "display(workflow_widget)\n",
    "print(f\"\\nSelected: {workflow_widget.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c874a",
   "metadata": {},
   "source": [
    "## 7. Workflow Descriptions\n",
    "\n",
    "Understand what each workflow does before executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51211faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflows_info = {\n",
    "    'move_preprocessed': {\n",
    "        'name': 'Move Preprocessed Files',\n",
    "        'description': 'Move already preprocessed files from old location to preprocessed folder',\n",
    "        'input': 'preprocessed_old/ (or custom path)',\n",
    "        'output': 'preprocessed/{seq}/{cond}/',\n",
    "        'notes': 'Requires metadata to match files with subjects'\n",
    "    },\n",
    "    'move2preprocess': {\n",
    "        'name': 'Move to Preprocess Queue',\n",
    "        'description': 'Move raw NIFTI files that need preprocessing',\n",
    "        'input': '3T/{seq}/{cond}/',\n",
    "        'output': 'TempData/{seq}/{cond}/{subject}-{series}-{image}/',\n",
    "        'notes': 'Prepares files for preprocessing, organized by subject'\n",
    "    },\n",
    "    'move2convert': {\n",
    "        'name': 'Move to Conversion Queue',\n",
    "        'description': 'Move DICOM files to conversion folder',\n",
    "        'input': 'DICOM/{seq}/{cond}/',\n",
    "        'output': '2convert/{seq}/{cond}/{subject}-{series}_{image}/',\n",
    "        'notes': 'Prepares for DICOM to NIfTI conversion'\n",
    "    },\n",
    "    'moveConverted': {\n",
    "        'name': 'Move Converted Files',\n",
    "        'description': 'Move converted NIfTI files to preprocessed folder',\n",
    "        'input': 'Converted/{seq}/{cond}/',\n",
    "        'output': 'preprocessed/{seq}/{cond}/',\n",
    "        'notes': 'Final step after DICOM conversion'\n",
    "    },\n",
    "    'freemove': {\n",
    "        'name': 'Free Move (Pattern-based)',\n",
    "        'description': 'Flexible file moving based on glob patterns',\n",
    "        'input': 'Custom path with glob pattern',\n",
    "        'output': 'Target directory with same structure',\n",
    "        'notes': 'Most flexible, useful for custom workflows'\n",
    "    },\n",
    "}\n",
    "\n",
    "def display_workflow_info(workflow_name):\n",
    "    info = workflows_info.get(workflow_name, {})\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Workflow: {info.get('name', 'Unknown')}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nDescription:\\n  {info.get('description', 'N/A')}\")\n",
    "    print(f\"\\nInput Directory:\\n  {info.get('input', 'N/A')}\")\n",
    "    print(f\"\\nOutput Directory:\\n  {info.get('output', 'N/A')}\")\n",
    "    print(f\"\\nNotes:\\n  {info.get('notes', 'N/A')}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "display_workflow_info(workflow_widget.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a84bdc",
   "metadata": {},
   "source": [
    "## 8. Execute Workflow\n",
    "\n",
    "Run the selected workflow with chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_button = widgets.Button(\n",
    "    description='â–¶ Execute Workflow',\n",
    "    button_style='success',\n",
    "    tooltip='Run the selected workflow'\n",
    ")\n",
    "\n",
    "execution_output = widgets.Output()\n",
    "\n",
    "def on_execute_clicked(b):\n",
    "    with execution_output:\n",
    "        clear_output()\n",
    "        try:\n",
    "            # Check metadata is loaded\n",
    "            if 'meta_df' not in globals():\n",
    "                print(\"âš  Error: Please load metadata first (Section 4)\")\n",
    "                return\n",
    "            \n",
    "            seq = seq_widget.value\n",
    "            cond = cond_widget.value\n",
    "            tesla = tesla_widget.value\n",
    "            divider = divider_widget.value\n",
    "            workflow = workflow_widget.value\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"Executing: {workflows_info[workflow]['name']}\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(f\"\\nParameters:\")\n",
    "            print(f\"  Sequence: {seq}\")\n",
    "            print(f\"  Condition: {cond}\")\n",
    "            print(f\"  Tesla: {tesla}T\")\n",
    "            print(f\"  Divider: {divider}\")\n",
    "            print(f\"\\nMetadata: {meta_df.shape[0]} records loaded\")\n",
    "            print(f\"\\nProcessing...\\n\")\n",
    "            \n",
    "            # Execute workflow\n",
    "            if workflow == 'move_preprocessed':\n",
    "                meta_dict, processed_indices = movePreprocessed(\n",
    "                    meta_df, \"./preprocessed_old\", seq, cond, tesla, divider\n",
    "                )\n",
    "                print(f\"\\nâœ“ Complete!\")\n",
    "                print(f\"  Unprocessed records: {len(meta_dict['Subject'])}\")\n",
    "                \n",
    "            elif workflow == 'move2preprocess':\n",
    "                count = move2preprocess(meta_df, seq, cond, tesla, divider)\n",
    "                print(f\"\\nâœ“ Complete!\")\n",
    "                print(f\"  Files moved: {count}\")\n",
    "                \n",
    "            elif workflow == 'move2convert':\n",
    "                count = move2convert(meta_df, seq, cond, tesla, divider)\n",
    "                print(f\"\\nâœ“ Complete!\")\n",
    "                print(f\"  Files moved: {count}\")\n",
    "                \n",
    "            elif workflow == 'moveConverted':\n",
    "                count = moveConverted(meta_df, seq, cond, tesla, divider)\n",
    "                print(f\"\\nâœ“ Complete!\")\n",
    "                print(f\"  Files moved: {count}\")\n",
    "                \n",
    "            elif workflow == 'freemove':\n",
    "                print(\"\\nâš  Free move requires source/target paths\")\n",
    "                print(\"  Use: freemove(source, target, seq, cond, tesla, file_format)\")\n",
    "            \n",
    "            print(f\"\\n{'='*70}\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "execute_button.on_click(on_execute_clicked)\n",
    "\n",
    "display(execute_button)\n",
    "display(execution_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d42af",
   "metadata": {},
   "source": [
    "## 9. Metadata Filtering & Visualization\n",
    "\n",
    "Explore and filter metadata interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'meta_df' in globals():\n",
    "    print(f\"Metadata Overview:\")\n",
    "    print(f\"  Total Records: {len(meta_df)}\")\n",
    "    print(f\"  Columns: {list(meta_df.columns)}\")\n",
    "    print(f\"\\nUnique Values:\")\n",
    "    \n",
    "    if 'Group' in meta_df.columns:\n",
    "        print(f\"  Groups: {meta_df['Group'].unique().tolist()}\")\n",
    "    if 'Sex' in meta_df.columns:\n",
    "        print(f\"  Sex: {meta_df['Sex'].unique().tolist()}\")\n",
    "    if 'Modality' in meta_df.columns:\n",
    "        print(f\"  Modalities: {meta_df['Modality'].unique().tolist()}\")\n",
    "    \n",
    "    # Create filter widgets\n",
    "    print(f\"\\n\\nFilter Metadata:\")\n",
    "    \n",
    "    filter_group = widgets.Dropdown(\n",
    "        options=['All'] + meta_df['Group'].unique().tolist() if 'Group' in meta_df.columns else ['All'],\n",
    "        description='Group:',\n",
    "        style={'description_width': '100px'}\n",
    "    )\n",
    "    \n",
    "    filter_sex = widgets.Dropdown(\n",
    "        options=['All'] + meta_df['Sex'].unique().tolist() if 'Sex' in meta_df.columns else ['All'],\n",
    "        description='Sex:',\n",
    "        style={'description_width': '100px'}\n",
    "    )\n",
    "    \n",
    "    filter_button = widgets.Button(description='Apply Filter', button_style='warning')\n",
    "    filter_output = widgets.Output()\n",
    "    \n",
    "    def on_filter_clicked(b):\n",
    "        with filter_output:\n",
    "            clear_output()\n",
    "            filtered = meta_df.copy()\n",
    "            \n",
    "            if filter_group.value != 'All':\n",
    "                filtered = filtered[filtered['Group'] == filter_group.value]\n",
    "            if filter_sex.value != 'All':\n",
    "                filtered = filtered[filtered['Sex'] == filter_sex.value]\n",
    "            \n",
    "            print(f\"\\nFiltered Results: {len(filtered)} records\")\n",
    "            display(filtered[['Subject', 'Group', 'Sex', 'Age', 'Modality', 'Visit']].head(10))\n",
    "    \n",
    "    filter_button.on_click(on_filter_clicked)\n",
    "    \n",
    "    display(filter_group)\n",
    "    display(filter_sex)\n",
    "    display(filter_button)\n",
    "    display(filter_output)\n",
    "else:\n",
    "    print(\"âš  Please load metadata first (Section 4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524074a6",
   "metadata": {},
   "source": [
    "## 10. Refresh Status\n",
    "\n",
    "Check pipeline status after running workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fde44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_button = widgets.Button(description='ðŸ”„ Refresh Status', button_style='info')\n",
    "refresh_output = widgets.Output()\n",
    "\n",
    "def on_refresh_clicked(b):\n",
    "    with refresh_output:\n",
    "        clear_output()\n",
    "        summary = get_directory_summary(str(BASE_DIR))\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"Updated Pipeline Status\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"\\nFile Counts by Directory:\")\n",
    "        for name, count in summary.items():\n",
    "            print(f\"  {name}: {count}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "refresh_button.on_click(on_refresh_clicked)\n",
    "\n",
    "display(refresh_button)\n",
    "display(refresh_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdbba00",
   "metadata": {},
   "source": [
    "## 11. Advanced: Custom Function Calls\n",
    "\n",
    "For advanced users: Call functions directly with custom parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Direct function calls\n",
    "\n",
    "# Example 1: Export metadata to CSV\n",
    "# from libs.metadata import exportCSV\n",
    "# meta_dict = {...}  # your metadata dict\n",
    "# exportCSV(meta_dict, \"my_metadata\", output_dir=\"./TempMeta/\")\n",
    "\n",
    "# Example 2: Filter metadata\n",
    "# from libs.metadata import filterMetadata\n",
    "# filtered_df = filterMetadata(meta_df, Group='AD', Sex='M')\n",
    "\n",
    "# Example 3: Create combined ID strings for matching\n",
    "# from libs.metadata import createMetaCombinedString\n",
    "# combined_ids = createMetaCombinedString(meta_df)\n",
    "# print(combined_ids[:5])  # First 5 combined IDs\n",
    "\n",
    "print(\"Uncomment and modify examples above to use custom function calls.\")\n",
    "print(\"\\nAll functions from libs are available:\")\n",
    "print(\"  â€¢ libs.file_operations\")\n",
    "print(\"  â€¢ libs.metadata\")\n",
    "print(\"  â€¢ libs.utils\")\n",
    "print(\"  â€¢ libs.config\")\n",
    "print(\"  â€¢ libs.logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de254a9c",
   "metadata": {},
   "source": [
    "## 12. Troubleshooting & Tips\n",
    "\n",
    "Common issues and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "troubleshooting = \"\"\"\n",
    "COMMON ISSUES & SOLUTIONS\n",
    "========================\n",
    "\n",
    "1. \"Metadata file not found\"\n",
    "   â†’ Ensure metadata CSV files are in TempMeta/ directory\n",
    "   â†’ Run: ensure_output_directories(str(BASE_DIR))\n",
    "\n",
    "2. \"No files found during move operation\"\n",
    "   â†’ Check source directory structure matches expectations\n",
    "   â†’ Verify directory validation in Section 2 passes\n",
    "   â†’ Check filename patterns (raw_, br_, Br_)\n",
    "\n",
    "3. \"ModuleNotFoundError: No module named 'libs'\"\n",
    "   â†’ Restart the kernel\n",
    "   â†’ Ensure notebook is in ADNI-processing/ directory\n",
    "   â†’ Check sys.path.insert in Section 1\n",
    "\n",
    "4. \"Unmatched metadata records\"\n",
    "   â†’ Metadata combined IDs don't match filenames\n",
    "   â†’ Check divider parameter (raw_, br_, Br_)\n",
    "   â†’ Verify filename format: ADNI_[ID]_MR[divider][SERIES]_I[IMAGE]\n",
    "\n",
    "5. \"Permission denied when moving files\"\n",
    "   â†’ Ensure target directories are writable\n",
    "   â†’ Check Windows file permissions\n",
    "   â†’ Try running with administrator privileges\n",
    "\n",
    "FOR BATCH PROCESSING:\n",
    "â†’ Use shell scripts in scripts/ directory instead\n",
    "â†’ run_pipeline.sh for fully automated pipeline\n",
    "\n",
    "FOR DEBUGGING:\n",
    "â†’ Add breakpoints and check variables\n",
    "â†’ Use print_pipeline_status() to inspect state\n",
    "â†’ Check logs in outputs/logs/ directory\n",
    "\"\"\"\n",
    "\n",
    "print(troubleshooting)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
